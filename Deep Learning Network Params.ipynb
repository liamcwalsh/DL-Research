{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Deep Learning Network Params</h1>\n",
    "We are interested in looking at how different networks can result in different accuracies, as well as how the number of free parameters can affect this.\n",
    "\n",
    "One of the very first things we did was look at the accuracy of a NN with a single hidden layer on the MNIST dataset. We found that the accuracy peaked at about 96%, and this was with 1000 hidden units. We then looked into how adding a second layer can add power to a network.  Specifically, we looked at how we could hit this 96% accuracy rate with 2 layers while using less parameters.\n",
    "\n",
    "Note that unless otherwise specified, the training regimen was with <strong>90000 iterations, batch size of 1 </strong>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Network Architecture| Layer 1    | Layer 2       | Accuracy         | Total # Params    |\n",
    "|--------------------|------------|---------------|------------------|-------------------|\n",
    "|1 hidden layer      | 1000       | ---           | 96.12%           | 795010            |\n",
    "|2 hidden layers     | 175        | 25            | 96.12%           | 142035            |\n",
    "|2 hidden layers     | 150        | 50            | 96.1%            | 125810            |\n",
    "|2 hidden layers     | 100        | 100           | 96.13%           | 89610             |\n",
    "|2 hidden layers     |<strong>85</strong>|<strong>80</strong>|<strong>96.05%</strong>|<strong>74415</strong>| \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it turns out, 85, 80 is the smallest possible 2 layer that could consistantly get 96% accuracy - permutations of smaller layer sizes resulted in sub 96% accuracies. The improvement from 1 layers to 2 layers in terms of drop in params is astounding - the 85, 80 uses just 9.36% of the params that the 1 layer uses, and hits the same accuracy!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we looked at the best results for a 2 layer net. According to Yan LeCun's page, the best accuracy for a regular 2 layer net is 96.95%:\n",
    "\n",
    "| Layer 1    | Layer 2       | Accuracy         | Total # Params |\n",
    "|------------|---------------|------------------|----------------|\n",
    "| 300        | 100           | 96.95%           |    266610      |\n",
    "| 290        | 100           | 97%              |    257760      |\n",
    "| <strong>250</strong>|<strong>125</strong>| <strong>96.97%</strong>|<strong>228885</strong>|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we looked at CNNs. These allowed for even more parameter reduction:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Filter Size| Number of Filters| Layer 1    | Layer 2       | Accuracy         | Total # Params|\n",
    "|-----------|------------------|------------|---------------|------------------|---------|\n",
    "| <strong>5x5</strong>|<strong>10</strong>|<strong>40</strong>|<strong>30</strong>|<strong>96.78%</strong>|<strong>80230</strong>   |     \n",
    "| 5x5       |5                 | 90         | 50            | 96.55%           | 92465   |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The smallest param network I found was LeNet 1, which is fully convolutional. It's a layer of 4 5x5 filters, followed by max pooling, followed by a layer of 12 filters, then max pooling, and then fully connected to the output 10 layer.  This in total is <strong>3230</strong> params, for 98.3% accuracy! Here's what the first layer filters look like:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](code/filtered_imgs.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
